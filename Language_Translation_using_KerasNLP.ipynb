{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGMBt8Z6uH2F"
      },
      "source": [
        "# **University of Madras,Guindy Campus**#\n",
        "# **Department of Computer Science**\n",
        "**II M.Sc Computer Science**\n",
        "\n",
        "Team-1:\n",
        "\n",
        "Angel Sarah Josephine B 36822101\n",
        "\n",
        "Deepika M 36822102\n",
        "\n",
        "Rithish R 36822112\n",
        "\n",
        "Singavarapu Rohit Roy 36822113\n",
        "\n",
        "Sunil Kumar M 36822114\n",
        "\n",
        "Syed Aljibre A 36822115\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qaeV95t6XbaM"
      },
      "outputs": [],
      "source": [
        "class Config:\n",
        "    vocab_size = 15000 # Vocabulary Size\n",
        "    sequence_length = 20\n",
        "    batch_size = 20\n",
        "    validation_split = 0.3\n",
        "    embed_dim = 256\n",
        "    latent_dim = 256\n",
        "    num_heads = 2\n",
        "    epochs = 10 # Number of Epochs to train\n",
        "    start_token = \"[start]\"\n",
        "    end_token = \"[end]\"\n",
        "config = Config()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dx-l3eQNZAvE",
        "outputId": "28425994-f67d-4565-fc25-2b469da0292e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras-nlp in /usr/local/lib/python3.10/dist-packages (0.6.3)\n",
            "Requirement already satisfied: keras-core in /usr/local/lib/python3.10/dist-packages (from keras-nlp) (0.1.7)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras-nlp) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras-nlp) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-nlp) (23.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from keras-nlp) (2023.6.3)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras-nlp) (13.7.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from keras-nlp) (0.1.8)\n",
            "Requirement already satisfied: tensorflow-text in /usr/local/lib/python3.10/dist-packages (from keras-nlp) (2.15.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras-core->keras-nlp) (0.0.7)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras-core->keras-nlp) (3.9.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-nlp) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-nlp) (2.16.1)\n",
            "Requirement already satisfied: tensorflow-hub>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text->keras-nlp) (0.15.0)\n",
            "Requirement already satisfied: tensorflow<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text->keras-nlp) (2.15.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras-nlp) (0.1.2)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (3.3.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (0.34.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (1.59.2)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (2.15.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (0.41.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (3.2.2)\n",
            "Requirement already satisfied: rouge-score in /usr/local/lib/python3.10/dist-packages (0.1.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.23.5)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (4.66.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install keras-nlp --upgrade\n",
        "!pip install rouge-score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ubCdzTLHZ-BI"
      },
      "outputs": [],
      "source": [
        "import keras_nlp\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from keras.layers import TextVectorization\n",
        "import pathlib\n",
        "import random\n",
        "import string\n",
        "import re\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm.notebook import tqdm\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Out5nuLP0yMl",
        "outputId": "9040e9d8-a1ae-4020-cea5-f007eca342a3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8f25a42c-3523-413e-956d-f8fd2c1e9719\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english</th>\n",
              "      <th>tamil</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Go.</td>\n",
              "      <td>போ.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Go.</td>\n",
              "      <td>போ.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Go.</td>\n",
              "      <td>போ.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Go.</td>\n",
              "      <td>போ.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>வணக்கம்.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8f25a42c-3523-413e-956d-f8fd2c1e9719')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8f25a42c-3523-413e-956d-f8fd2c1e9719 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8f25a42c-3523-413e-956d-f8fd2c1e9719');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a3e819ed-ba27-42eb-91b5-72eb7536cbe9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a3e819ed-ba27-42eb-91b5-72eb7536cbe9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a3e819ed-ba27-42eb-91b5-72eb7536cbe9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "  english     tamil\n",
              "0     Go.      போ.\n",
              "1     Go.      போ.\n",
              "2     Go.      போ.\n",
              "3     Go.      போ.\n",
              "4     Hi.  வணக்கம்."
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = pd.read_excel(\"/content/data - Copy.xlsx\")\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HcOJzQ8N446B"
      },
      "outputs": [],
      "source": [
        "data[\"tamil\"] = data[\"tamil\"].apply(lambda item: f\"{config.start_token} \" + item + f\" {config.end_token}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tIbdwo_C04cG"
      },
      "outputs": [],
      "source": [
        "strip_chars = string.punctuation + \"¿\"\n",
        "strip_chars = strip_chars.replace(\"[\", \"\")\n",
        "strip_chars = strip_chars.replace(\"]\", \"\")\n",
        "def tamil_standardize(input_string):\n",
        "    lowercase = tf.strings.lower(input_string)\n",
        "    return tf.strings.regex_replace(lowercase, \"[%s]\"%re.escape(strip_chars), \"\")\n",
        "english_vectorization = TextVectorization(\n",
        "    max_tokens=config.vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=config.sequence_length,\n",
        ")\n",
        "tamil_vectorization = TextVectorization(\n",
        "    max_tokens=config.vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=config.sequence_length + 1,\n",
        "    standardize=tamil_standardize,\n",
        ")\n",
        "\n",
        "english_vectorization.adapt(list(data[\"english\"]))\n",
        "tamil_vectorization.adapt(list(data[\"tamil\"]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dYAGhBZo1V5f"
      },
      "outputs": [],
      "source": [
        "def preprocess(english, tamil):\n",
        "    english = english_vectorization(english)\n",
        "    tamil = tamil_vectorization(tamil)\n",
        "    return ({\"encoder_inputs\": english, \"decoder_inputs\": tamil[:, :-1]}, tamil[:, 1:])\n",
        "def make_dataset(df, batch_size, mode):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((list(df[\"english\"]), list(df[\"tamil\"])))\n",
        "    if mode == \"train\":\n",
        "       dataset = dataset.shuffle(batch_size * 4)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.map(preprocess)\n",
        "    dataset = dataset.prefetch(tf.data.AUTOTUNE).cache()\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5RDnxKZ1ZX0",
        "outputId": "215986d4-423e-4974-ed89-3d6c6f49c2d5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((17500, 2), (7500, 2))"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train, valid = train_test_split(data, test_size=config.validation_split)\n",
        "train.shape, valid.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EArTDsnv1blq"
      },
      "outputs": [],
      "source": [
        "train_ds = make_dataset(train, batch_size=config.batch_size, mode=\"train\")\n",
        "valid_ds = make_dataset(valid, batch_size=config.batch_size, mode=\"valid\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BD7FKI951g18"
      },
      "outputs": [],
      "source": [
        "def get_model(config):\n",
        "    encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
        "    x = keras_nlp.layers.TokenAndPositionEmbedding(\n",
        "        config.vocab_size,\n",
        "        config.sequence_length,\n",
        "        config.embed_dim,\n",
        "        mask_zero=True\n",
        "    )(encoder_inputs)\n",
        "    encoder_outputs = keras_nlp.layers.TransformerEncoder(intermediate_dim=config.embed_dim, num_heads=config.num_heads)(x)\n",
        "    encoder = keras.Model(encoder_inputs, encoder_outputs)\n",
        "\n",
        "    decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n",
        "    encoded_seq_inputs = keras.Input(shape=(None, config.embed_dim), name=\"decoder_state_inputs\")\n",
        "    x = keras_nlp.layers.TokenAndPositionEmbedding(\n",
        "        config.vocab_size,\n",
        "        config.sequence_length,\n",
        "        config.embed_dim,\n",
        "        mask_zero=True\n",
        "    )(decoder_inputs)\n",
        "    x = keras_nlp.layers.TransformerDecoder(config.latent_dim, config.num_heads)(x, encoded_seq_inputs)\n",
        "    x = layers.Dropout(0.1)(x)\n",
        "    decoder_outputs = layers.Dense(config.vocab_size, activation=\"softmax\")(x)\n",
        "    decoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n",
        "\n",
        "    decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n",
        "    transformer = keras.Model(\n",
        "        [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n",
        "    )\n",
        "    transformer.compile(\n",
        "        \"adam\",\n",
        "        loss=\"sparse_categorical_crossentropy\",\n",
        "        metrics=[\n",
        "            \"accuracy\"\n",
        "        ]\n",
        "    )\n",
        "    return transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJxHkmxI1lNs"
      },
      "outputs": [],
      "source": [
        "model_ta = get_model(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDb_iwUJ1tgR",
        "outputId": "b0776d97-16c4-48db-a927-67406abd3990"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "875/875 [==============================] - 520s 576ms/step - loss: 3.3382 - accuracy: 0.5621 - val_loss: 2.5571 - val_accuracy: 0.6391\n",
            "Epoch 2/10\n",
            "875/875 [==============================] - 485s 554ms/step - loss: 1.8010 - accuracy: 0.6977 - val_loss: 2.0364 - val_accuracy: 0.7039\n",
            "Epoch 3/10\n",
            "875/875 [==============================] - 480s 549ms/step - loss: 1.0176 - accuracy: 0.7830 - val_loss: 1.9198 - val_accuracy: 0.7270\n",
            "Epoch 4/10\n",
            "875/875 [==============================] - 476s 544ms/step - loss: 0.6012 - accuracy: 0.8513 - val_loss: 1.9568 - val_accuracy: 0.7319\n",
            "Epoch 5/10\n",
            "875/875 [==============================] - 470s 537ms/step - loss: 0.4118 - accuracy: 0.8933 - val_loss: 2.0324 - val_accuracy: 0.7329\n",
            "Epoch 6/10\n",
            "875/875 [==============================] - 491s 561ms/step - loss: 0.3304 - accuracy: 0.9115 - val_loss: 2.0383 - val_accuracy: 0.7509\n",
            "Epoch 7/10\n",
            "875/875 [==============================] - 465s 531ms/step - loss: 0.2816 - accuracy: 0.9222 - val_loss: 2.0730 - val_accuracy: 0.7560\n",
            "Epoch 8/10\n",
            "875/875 [==============================] - 487s 556ms/step - loss: 0.2440 - accuracy: 0.9309 - val_loss: 2.1342 - val_accuracy: 0.7526\n",
            "Epoch 9/10\n",
            "875/875 [==============================] - 471s 538ms/step - loss: 0.2286 - accuracy: 0.9347 - val_loss: 2.1711 - val_accuracy: 0.7586\n",
            "Epoch 10/10\n",
            "875/875 [==============================] - 472s 540ms/step - loss: 0.2129 - accuracy: 0.9387 - val_loss: 2.1959 - val_accuracy: 0.7601\n",
            "875/875 [==============================] - 155s 177ms/step - loss: 0.2973 - accuracy: 0.9163\n",
            "Accuracy Of Tamil: 91.6260\n"
          ]
        }
      ],
      "source": [
        "checkpoints = tf.keras.callbacks.ModelCheckpoint(\n",
        "    \"model_ta.tf\",\n",
        "    monitor=\"val_accuracy\",\n",
        "    mode=\"min\",\n",
        "    save_best_only=True\n",
        ")\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(\n",
        "    patience=10,\n",
        "    monitor=\"val_loss\",\n",
        "    mode=\"min\",\n",
        "    restore_best_weights=True\n",
        ")\n",
        "history = model_ta.fit(train_ds, epochs=config.epochs, validation_data=valid_ds, callbacks=[checkpoints, early_stop])\n",
        "accuracy = model_ta.evaluate(train_ds, return_dict=True)['accuracy']\n",
        "print(f'Accuracy Of Tamil: {accuracy*100:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRHxLTNi25jo",
        "outputId": "c7a64ed1-50b1-4363-b88f-f728b4d22603"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " encoder_inputs (InputLayer  [(None, None)]               0         []                            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " token_and_position_embeddi  (None, None, 256)            3845120   ['encoder_inputs[0][0]']      \n",
            " ng (TokenAndPositionEmbedd                                                                       \n",
            " ing)                                                                                             \n",
            "                                                                                                  \n",
            " decoder_inputs (InputLayer  [(None, None)]               0         []                            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " transformer_encoder (Trans  (None, None, 256)            395776    ['token_and_position_embedding\n",
            " formerEncoder)                                                     [0][0]']                      \n",
            "                                                                                                  \n",
            " model_1 (Functional)        (None, None, 15000)          8359576   ['decoder_inputs[0][0]',      \n",
            "                                                                     'transformer_encoder[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 12600472 (48.07 MB)\n",
            "Trainable params: 12600472 (48.07 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "loaded_model_ta = tf.keras.models.load_model(\"model_ta.tf\", custom_objects={\n",
        "    \"TokenAndPositionEmbedding\": keras_nlp.layers.TokenAndPositionEmbedding,\n",
        "    \"TransformerEncoder\": keras_nlp.layers.TransformerEncoder,\n",
        "    \"TransformerDecoder\": keras_nlp.layers.TransformerDecoder\n",
        "})\n",
        "loaded_model_ta.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "uDt0ls0VWvbL"
      },
      "outputs": [],
      "source": [
        "tamil_vocab = tamil_vectorization.get_vocabulary()\n",
        "tamil_index_lookup = dict(zip(range(len(tamil_vocab)), tamil_vocab))\n",
        "start_index = tamil_vocab.index(config.start_token)\n",
        "end_index = tamil_vocab.index(config.end_token)\n",
        "unk_index = tamil_vocab.index(\"[UNK]\")\n",
        "def decode_sequence_ta(model_ta, input_sentence, filtered_values = [start_index, end_index, unk_index]):\n",
        "    tokenized_input_sentence = english_vectorization([input_sentence])\n",
        "    decoded_sentence = [start_index] + [0] * (config.sequence_length)\n",
        "    for i in range(config.sequence_length):\n",
        "        decoded_sentence_constant = tf.constant([decoded_sentence[:config.sequence_length]])\n",
        "        predictions = model_ta([tokenized_input_sentence, decoded_sentence_constant])\n",
        "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
        "        decoded_sentence[i + 1] = sampled_token_index\n",
        "        if sampled_token_index == end_index:\n",
        "            break\n",
        "    components = [tamil_index_lookup[c] for c in decoded_sentence if c not in filtered_values]\n",
        "    return \" \".join(components)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 592,
          "referenced_widgets": [
            "c49409961d21456fbea6a908bb377dab",
            "8c46869b0dd948b08a12c65d2acab800",
            "aa64439777404f7ea934d8364f1f9089",
            "b71a376a7c3644389df03183fd3238f5",
            "5d61818451b64fca9f1a4669558586bb",
            "2b50c797055c4bad8d01c5465035d8be",
            "d85750bbbc2b41f683c50c579d983eaa",
            "8c5b7fb222844b2e8464860efd0887e0",
            "f7e1a3d9f0b94f06a3b2cfc775b461c6",
            "b749c02cb73b47158aaecbe53bac8d76",
            "2d36b94d59da485b86d492751b078bb3"
          ]
        },
        "id": "fkPQWDq9W0jj",
        "outputId": "a2060acc-f57a-45a1-9519-cd3c498fb257"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c49409961d21456fbea6a908bb377dab",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "English: Help yourself.\n",
            "tamil: உங்களுக்கு உதவுங்கள்.\n",
            "Translated: நீங்கள் யாரை                 \n",
            "English: Are you imitating me?\n",
            "tamil: நீங்கள் என்னைப் பின்பற்றுகிறீர்களா?\n",
            "Translated: நீங்கள் என்னை அழையுங்கள்                \n",
            "English: He is at his office.\n",
            "tamil: அவர் தனது அலுவலகத்தில் இருக்கிறார்.\n",
            "Translated: அவர் தனது பெயரை இருக்கிறார்               \n",
            "English: I fell asleep.\n",
            "tamil: நான் தூங்கிவிட்டேன்.\n",
            "Translated: நான் கணிதத்தை                 \n",
            "English: You're mean.\n",
            "tamil: நீங்கள் சராசரி.\n",
            "Translated: நீங்கள் சராசரி                 \n",
            "English: Even Tom smiled.\n",
            "tamil: டாம் கூட சிரித்தார்.\n",
            "Translated: டாம் கூறினார்                 \n",
            "English: Stop right here.\n",
            "tamil: இங்கேயே நிறுத்துங்கள்.\n",
            "Translated: இங்கே வாருங்கள்                 \n",
            "English: I left.\n",
            "tamil: நான் வெளியேறினேன்.\n",
            "Translated: நான் உன்னைப்                 \n",
            "English: Let me call Tom.\n",
            "tamil: நான் டாம் என்று அழைக்கிறேன்.\n",
            "Translated: டாம் என்னை மறந்து விடுங்கள்               \n",
            "English: Let's vote.\n",
            "tamil: வாக்களிப்போம்.\n",
            "Translated: டாம் அக்கறை                 \n"
          ]
        }
      ],
      "source": [
        "for i in tqdm(np.random.choice(len(data), 10)):\n",
        "    item = data.iloc[i]\n",
        "    translated = decode_sequence_ta(loaded_model_ta, item[\"english\"])\n",
        "    print(\"English:\", item[\"english\"])\n",
        "    print(\"tamil:\", item[\"tamil\"].replace(\"[start] \", \"\").replace(\" [end]\", \"\"))\n",
        "    print(\"Translated:\", translated)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "tnbYTif5peik",
        "outputId": "05265220-d318-4038-d130-33ad0222d906"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f9e82e98-0aea-4933-a15d-ff189960a736\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english</th>\n",
              "      <th>hindi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Go.</td>\n",
              "      <td>जाना।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Go.</td>\n",
              "      <td>जाना।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Go.</td>\n",
              "      <td>जाना।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Go.</td>\n",
              "      <td>जाना।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>नमस्ते।</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f9e82e98-0aea-4933-a15d-ff189960a736')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f9e82e98-0aea-4933-a15d-ff189960a736 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f9e82e98-0aea-4933-a15d-ff189960a736');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-155da368-cb89-4df6-931c-64a788e8f527\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-155da368-cb89-4df6-931c-64a788e8f527')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-155da368-cb89-4df6-931c-64a788e8f527 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "  english    hindi\n",
              "0     Go.    जाना।\n",
              "1     Go.    जाना।\n",
              "2     Go.    जाना।\n",
              "3     Go.    जाना।\n",
              "4     Hi.  नमस्ते।"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_hi = pd.read_csv(\"/content/hindi - data.csv\")\n",
        "data_hi.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IJ-gOZYIplgJ"
      },
      "outputs": [],
      "source": [
        "data_hi[\"hindi\"] = data_hi[\"hindi\"].apply(lambda item: f\"{config.start_token} \" + item + f\" {config.end_token}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tyomYHvgpoJH"
      },
      "outputs": [],
      "source": [
        "def hindi_standardize(input_string):\n",
        "    lowercase = tf.strings.lower(input_string)\n",
        "    return tf.strings.regex_replace(lowercase, \"[%s]\"%re.escape(strip_chars), \"\")\n",
        "english_vectorization = TextVectorization(\n",
        "    max_tokens=config.vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=config.sequence_length,\n",
        ")\n",
        "hindi_vectorization = TextVectorization(\n",
        "    max_tokens=config.vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=config.sequence_length + 1,\n",
        "    standardize=hindi_standardize,\n",
        ")\n",
        "english_vectorization.adapt(list(data_hi[\"english\"]))\n",
        "hindi_vectorization.adapt(list(data_hi[\"hindi\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KZFDcM-mpwga"
      },
      "outputs": [],
      "source": [
        "def preprocess(english, hindi):\n",
        "    english = english_vectorization(english)\n",
        "    hindi = hindi_vectorization(hindi)\n",
        "    return ({\"encoder_inputs\": english, \"decoder_inputs\": hindi[:, :-1]}, hindi[:, 1:])\n",
        "def make_dataset(df, batch_size, mode):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((list(df[\"english\"]), list(df[\"hindi\"])))\n",
        "    if mode == \"train\":\n",
        "       dataset = dataset.shuffle(batch_size * 4)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.map(preprocess)\n",
        "    dataset = dataset.prefetch(tf.data.AUTOTUNE).cache()\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wPmXecLtpxt-",
        "outputId": "87ce1e3c-16f9-4ca8-8b47-ade206620162"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((17500, 2), (7500, 2))"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train, valid = train_test_split(data_hi, test_size=config.validation_split)\n",
        "train.shape, valid.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PPgqgcY7p0BG"
      },
      "outputs": [],
      "source": [
        "train_ds = make_dataset(train, batch_size=config.batch_size, mode=\"train\")\n",
        "valid_ds = make_dataset(valid, batch_size=config.batch_size, mode=\"valid\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "XK7MF_A2p2r2"
      },
      "outputs": [],
      "source": [
        "def get_model(config):\n",
        "    encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
        "    x = keras_nlp.layers.TokenAndPositionEmbedding(\n",
        "        config.vocab_size,\n",
        "        config.sequence_length,\n",
        "        config.embed_dim,\n",
        "        mask_zero=True\n",
        "    )(encoder_inputs)\n",
        "    encoder_outputs = keras_nlp.layers.TransformerEncoder(intermediate_dim=config.embed_dim, num_heads=config.num_heads)(x)\n",
        "    encoder = keras.Model(encoder_inputs, encoder_outputs)\n",
        "\n",
        "    decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n",
        "    encoded_seq_inputs = keras.Input(shape=(None, config.embed_dim), name=\"decoder_state_inputs\")\n",
        "    x = keras_nlp.layers.TokenAndPositionEmbedding(\n",
        "        config.vocab_size,\n",
        "        config.sequence_length,\n",
        "        config.embed_dim,\n",
        "        mask_zero=True\n",
        "    )(decoder_inputs)\n",
        "    x = keras_nlp.layers.TransformerDecoder(config.latent_dim, config.num_heads)(x, encoded_seq_inputs)\n",
        "    x = layers.Dropout(0.1)(x)\n",
        "    decoder_outputs = layers.Dense(config.vocab_size, activation=\"softmax\")(x)\n",
        "    decoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n",
        "\n",
        "    decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n",
        "    transformer = keras.Model(\n",
        "        [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n",
        "    )\n",
        "    transformer.compile(\n",
        "        \"adam\",\n",
        "        loss=\"sparse_categorical_crossentropy\",\n",
        "        metrics=[\n",
        "            \"accuracy\"\n",
        "        ]\n",
        "    )\n",
        "    return transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UtxwQN84qDk2"
      },
      "outputs": [],
      "source": [
        "model_hi = get_model(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uDx9Alq9qIMU"
      },
      "outputs": [],
      "source": [
        "checkpoints = tf.keras.callbacks.ModelCheckpoint(\n",
        "    \"model_hi.tf\",\n",
        "    monitor=\"val_accuracy\",\n",
        "    mode=\"min\",\n",
        "    save_best_only=True\n",
        ")\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(\n",
        "    patience=10,\n",
        "    monitor=\"val_loss\",\n",
        "    mode=\"min\",\n",
        "    restore_best_weights=True\n",
        ")\n",
        "history = model_hi.fit(train_ds, epochs=config.epochs, validation_data=valid_ds, callbacks=[checkpoints, early_stop])\n",
        "accuracy = model_hi.evaluate(train_ds, return_dict=True)['accuracy']\n",
        "print(f'Accuracy of Hindi: {accuracy*100:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "28SzFXrgqUvs"
      },
      "outputs": [],
      "source": [
        "loaded_model_hi = tf.keras.models.load_model(\"model_hi.tf\", custom_objects={\n",
        "    \"TokenAndPositionEmbedding\": keras_nlp.layers.TokenAndPositionEmbedding,\n",
        "    \"TransformerEncoder\": keras_nlp.layers.TransformerEncoder,\n",
        "    \"TransformerDecoder\": keras_nlp.layers.TransformerDecoder\n",
        "})\n",
        "loaded_model_hi.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "u3Y0Iz-zqqdo"
      },
      "outputs": [],
      "source": [
        "hindi_vocab = hindi_vectorization.get_vocabulary()\n",
        "hindi_index_lookup = dict(zip(range(len(hindi_vocab)), hindi_vocab))\n",
        "start_index = hindi_vocab.index(config.start_token)\n",
        "end_index = hindi_vocab.index(config.end_token)\n",
        "unk_index = hindi_vocab.index(\"[UNK]\")\n",
        "def decode_sequence_hi(model_hi, input_sentence, filtered_values = [start_index, end_index, unk_index]):\n",
        "    tokenized_input_sentence = english_vectorization([input_sentence])\n",
        "    decoded_sentence = [start_index] + [0] * (config.sequence_length)\n",
        "    for i in range(config.sequence_length):\n",
        "        decoded_sentence_constant = tf.constant([decoded_sentence[:config.sequence_length]])\n",
        "        predictions = model_hi([tokenized_input_sentence, decoded_sentence_constant])\n",
        "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
        "        decoded_sentence[i + 1] = sampled_token_index\n",
        "        if sampled_token_index == end_index:\n",
        "            break\n",
        "    components = [hindi_index_lookup[c] for c in decoded_sentence if c not in filtered_values]\n",
        "    return \" \".join(components)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xj7AUoUuquVs"
      },
      "outputs": [],
      "source": [
        "for i in tqdm(np.random.choice(len(data_hi), 10)):\n",
        "    item = data_hi.iloc[i]\n",
        "    translated = decode_sequence_hi(loaded_model_hi, item[\"english\"])\n",
        "    print(\"English:\", item[\"english\"])\n",
        "    print(\"hindi:\", item[\"hindi\"].replace(\"[start] \", \"\").replace(\" [end]\", \"\"))\n",
        "    print(\"Translated:\", translated)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3ype_KD51udU"
      },
      "outputs": [],
      "source": [
        "data_ml = pd.read_csv(\"/content/Malayalam - data.csv\")\n",
        "data_ml.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jF7W4Gmr4ajQ"
      },
      "outputs": [],
      "source": [
        "data_ml[\"malayalam\"] = data_ml[\"malayalam\"].apply(lambda item: f\"{config.start_token} \" + item + f\" {config.end_token}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wINeKuxZ4duF"
      },
      "outputs": [],
      "source": [
        "strip_chars = string.punctuation + \"¿\"\n",
        "strip_chars = strip_chars.replace(\"[\", \"\")\n",
        "strip_chars = strip_chars.replace(\"]\", \"\")\n",
        "def malayalam_standardize(input_string):\n",
        "    lowercase = tf.strings.lower(input_string)\n",
        "    return tf.strings.regex_replace(lowercase, \"[%s]\"%re.escape(strip_chars), \"\")\n",
        "english_vectorization = TextVectorization(\n",
        "    max_tokens=config.vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=config.sequence_length,\n",
        ")\n",
        "malayalam_vectorization = TextVectorization(\n",
        "    max_tokens=config.vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=config.sequence_length + 1,\n",
        "    standardize=malayalam_standardize,\n",
        ")\n",
        "english_vectorization.adapt(list(data_ml[\"english\"]))\n",
        "malayalam_vectorization.adapt(list(data_ml[\"malayalam\"]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "d_otjRxQ4hOx"
      },
      "outputs": [],
      "source": [
        "def preprocess(english, malayalam):\n",
        "    english = english_vectorization(english)\n",
        "    malayalam = malayalam_vectorization(malayalam)\n",
        "    return ({\"encoder_inputs\": english, \"decoder_inputs\": malayalam[:, :-1]}, malayalam[:, 1:])\n",
        "def make_dataset(df, batch_size, mode):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((list(df[\"english\"]), list(df[\"malayalam\"])))\n",
        "    if mode == \"train\":\n",
        "       dataset = dataset.shuffle(batch_size * 4)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.map(preprocess)\n",
        "    dataset = dataset.prefetch(tf.data.AUTOTUNE).cache()\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Yx4vdAWN4nbP"
      },
      "outputs": [],
      "source": [
        "train, valid = train_test_split(data_ml, test_size=config.validation_split)\n",
        "train.shape, valid.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jDmtNB224p39"
      },
      "outputs": [],
      "source": [
        "train_ds = make_dataset(train, batch_size=config.batch_size, mode=\"train\")\n",
        "valid_ds = make_dataset(valid, batch_size=config.batch_size, mode=\"valid\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hesVtFgV4seC"
      },
      "outputs": [],
      "source": [
        "def get_model_ml(config):\n",
        "    encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
        "    x = keras_nlp.layers.TokenAndPositionEmbedding(\n",
        "        config.vocab_size,\n",
        "        config.sequence_length,\n",
        "        config.embed_dim,\n",
        "        mask_zero=True\n",
        "    )(encoder_inputs)\n",
        "    encoder_outputs = keras_nlp.layers.TransformerEncoder(intermediate_dim=config.embed_dim, num_heads=config.num_heads)(x)\n",
        "    encoder = keras.Model(encoder_inputs, encoder_outputs)\n",
        "\n",
        "    decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n",
        "    encoded_seq_inputs = keras.Input(shape=(None, config.embed_dim), name=\"decoder_state_inputs\")\n",
        "    x = keras_nlp.layers.TokenAndPositionEmbedding(\n",
        "        config.vocab_size,\n",
        "        config.sequence_length,\n",
        "        config.embed_dim,\n",
        "        mask_zero=True\n",
        "    )(decoder_inputs)\n",
        "    x = keras_nlp.layers.TransformerDecoder(config.latent_dim, config.num_heads)(x, encoded_seq_inputs)\n",
        "    x = layers.Dropout(0.1)(x)\n",
        "    decoder_outputs = layers.Dense(config.vocab_size, activation=\"softmax\")(x)\n",
        "    decoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n",
        "\n",
        "    decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n",
        "    transformer = keras.Model(\n",
        "        [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n",
        "    )\n",
        "    transformer.compile(\n",
        "        \"adam\",\n",
        "        loss=\"sparse_categorical_crossentropy\",\n",
        "        metrics=[\n",
        "            \"accuracy\"\n",
        "        ]\n",
        "    )\n",
        "    return transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "t6eLS4QW4xef"
      },
      "outputs": [],
      "source": [
        "model_ml = get_model_ml(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJ2LX1JI41IA"
      },
      "outputs": [],
      "source": [
        "checkpoints = tf.keras.callbacks.ModelCheckpoint(\n",
        "    \"model_ml.tf\",\n",
        "    monitor=\"val_accuracy\",\n",
        "    mode=\"min\",\n",
        "    save_best_only=True\n",
        ")\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(\n",
        "    patience=10,\n",
        "    monitor=\"val_loss\",\n",
        "    mode=\"min\",\n",
        "    restore_best_weights=True\n",
        ")\n",
        "history = model_ml.fit(train_ds, epochs=config.epochs, validation_data=valid_ds, callbacks=[checkpoints, early_stop])\n",
        "accuracy = model_ml.evaluate(train_ds, return_dict=True)['accuracy']\n",
        "print(f'Accuracy Of Malayalam: {accuracy*100:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBn4LnmQ5PHH"
      },
      "outputs": [],
      "source": [
        "loaded_model_ml = tf.keras.models.load_model(\"model_ml.tf\", custom_objects={\n",
        "    \"TokenAndPositionEmbedding\": keras_nlp.layers.TokenAndPositionEmbedding,\n",
        "    \"TransformerEncoder\": keras_nlp.layers.TransformerEncoder,\n",
        "    \"TransformerDecoder\": keras_nlp.layers.TransformerDecoder\n",
        "})\n",
        "loaded_model_ml.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4s4mcWW25Tge"
      },
      "outputs": [],
      "source": [
        "malayalam_vocab = malayalam_vectorization.get_vocabulary()\n",
        "malayalam_index_lookup = dict(zip(range(len(malayalam_vocab)), malayalam_vocab))\n",
        "start_index = malayalam_vocab.index(config.start_token)\n",
        "end_index = malayalam_vocab.index(config.end_token)\n",
        "unk_index = malayalam_vocab.index(\"[UNK]\")\n",
        "def decode_sequence_ml(model_ml, input_sentence, filtered_values = [start_index, end_index, unk_index]):\n",
        "    tokenized_input_sentence = english_vectorization([input_sentence])\n",
        "    decoded_sentence = [start_index] + [0] * (config.sequence_length)\n",
        "    for i in range(config.sequence_length):\n",
        "        decoded_sentence_constant = tf.constant([decoded_sentence[:config.sequence_length]])\n",
        "        predictions = model_ml([tokenized_input_sentence, decoded_sentence_constant])\n",
        "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
        "        decoded_sentence[i + 1] = sampled_token_index\n",
        "        if sampled_token_index == end_index:\n",
        "            break\n",
        "    components = [malayalam_index_lookup[c] for c in decoded_sentence if c not in filtered_values]\n",
        "    return \" \".join(components)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ak9sUfuM5Uae"
      },
      "outputs": [],
      "source": [
        "for i in tqdm(np.random.choice(len(data_ml), 10)):\n",
        "    item = data_ml.iloc[i]\n",
        "    translated = decode_sequence_ml(loaded_model_ml, item[\"english\"])\n",
        "    print(\"English:\", item[\"english\"])\n",
        "    print(\"malayalam:\", item[\"malayalam\"].replace(\"[start] \", \"\").replace(\" [end]\", \"\"))\n",
        "    print(\"Translated:\", translated)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YF7j9W7Z7AFD"
      },
      "outputs": [],
      "source": [
        "data_te = pd.read_csv(\"/content/telugu - data.csv\")\n",
        "data_te.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jBsVDSid7vi4"
      },
      "outputs": [],
      "source": [
        "data_te[\"telugu\"] = data_te[\"telugu\"].apply(lambda item: f\"{config.start_token} \" + item + f\" {config.end_token}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjCEEuvY7yce"
      },
      "outputs": [],
      "source": [
        "strip_chars = string.punctuation + \"¿\"\n",
        "strip_chars = strip_chars.replace(\"[\", \"\")\n",
        "strip_chars = strip_chars.replace(\"]\", \"\")\n",
        "def telugu_standardize(input_string):\n",
        "    lowercase = tf.strings.lower(input_string)\n",
        "    return tf.strings.regex_replace(lowercase, \"[%s]\"%re.escape(strip_chars), \"\")\n",
        "english_vectorization = TextVectorization(\n",
        "    max_tokens=config.vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=config.sequence_length,\n",
        ")\n",
        "telugu_vectorization = TextVectorization(\n",
        "    max_tokens=config.vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=config.sequence_length + 1,\n",
        "    standardize=telugu_standardize,\n",
        ")\n",
        "english_vectorization.adapt(list(data_te[\"english\"]))\n",
        "telugu_vectorization.adapt(list(data_te[\"telugu\"]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CfzPX8z273Pb"
      },
      "outputs": [],
      "source": [
        "def preprocess(english, telugu):\n",
        "    english = english_vectorization(english)\n",
        "    telugu = telugu_vectorization(telugu)\n",
        "    return ({\"encoder_inputs\": english, \"decoder_inputs\": telugu[:, :-1]}, telugu[:, 1:])\n",
        "def make_dataset(df, batch_size, mode):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((list(df[\"english\"]), list(df[\"telugu\"])))\n",
        "    if mode == \"train\":\n",
        "       dataset = dataset.shuffle(batch_size * 4)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.map(preprocess)\n",
        "    dataset = dataset.prefetch(tf.data.AUTOTUNE).cache()\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lZr79LBV76E3"
      },
      "outputs": [],
      "source": [
        "train, valid = train_test_split(data_te, test_size=config.validation_split)\n",
        "train.shape, valid.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O7U73Xh978dj"
      },
      "outputs": [],
      "source": [
        "train_ds = make_dataset(train, batch_size=config.batch_size, mode=\"train\")\n",
        "valid_ds = make_dataset(valid, batch_size=config.batch_size, mode=\"valid\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CC324D107_pE"
      },
      "outputs": [],
      "source": [
        "def get_model_te(config):\n",
        "    encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
        "    x = keras_nlp.layers.TokenAndPositionEmbedding(\n",
        "        config.vocab_size,\n",
        "        config.sequence_length,\n",
        "        config.embed_dim,\n",
        "        mask_zero=True\n",
        "    )(encoder_inputs)\n",
        "    encoder_outputs = keras_nlp.layers.TransformerEncoder(intermediate_dim=config.embed_dim, num_heads=config.num_heads)(x)\n",
        "    encoder = keras.Model(encoder_inputs, encoder_outputs)\n",
        "\n",
        "    decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n",
        "    encoded_seq_inputs = keras.Input(shape=(None, config.embed_dim), name=\"decoder_state_inputs\")\n",
        "    x = keras_nlp.layers.TokenAndPositionEmbedding(\n",
        "        config.vocab_size,\n",
        "        config.sequence_length,\n",
        "        config.embed_dim,\n",
        "        mask_zero=True\n",
        "    )(decoder_inputs)\n",
        "    x = keras_nlp.layers.TransformerDecoder(config.latent_dim, config.num_heads)(x, encoded_seq_inputs)\n",
        "    x = layers.Dropout(0.1)(x)\n",
        "    decoder_outputs = layers.Dense(config.vocab_size, activation=\"softmax\")(x)\n",
        "    decoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n",
        "\n",
        "    decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n",
        "    transformer = keras.Model(\n",
        "        [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n",
        "    )\n",
        "    transformer.compile(\n",
        "        \"adam\",\n",
        "        loss=\"sparse_categorical_crossentropy\",\n",
        "        metrics=[\n",
        "            \"accuracy\"\n",
        "        ]\n",
        "    )\n",
        "    return transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ml9r6nH48DiZ"
      },
      "outputs": [],
      "source": [
        "model_te = get_model_te(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UeMWJyOp8H9H"
      },
      "outputs": [],
      "source": [
        "checkpoints = tf.keras.callbacks.ModelCheckpoint(\n",
        "    \"model_te.tf\",\n",
        "    monitor=\"val_accuracy\",\n",
        "    mode=\"min\",\n",
        "    save_best_only=True\n",
        ")\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(\n",
        "    patience=10,\n",
        "    monitor=\"val_loss\",\n",
        "    mode=\"min\",\n",
        "    restore_best_weights=True\n",
        ")\n",
        "history = model_te.fit(train_ds, epochs=config.epochs, validation_data=valid_ds, callbacks=[checkpoints, early_stop])\n",
        "accuracy = model_te.evaluate(train_ds, return_dict=True)['accuracy']\n",
        "print(f'Accuracy of Telugu: {accuracy*100:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J2fUkPC38J89"
      },
      "outputs": [],
      "source": [
        "loaded_model_te = tf.keras.models.load_model(\"model_te.tf\", custom_objects={\n",
        "    \"TokenAndPositionEmbedding\": keras_nlp.layers.TokenAndPositionEmbedding,\n",
        "    \"TransformerEncoder\": keras_nlp.layers.TransformerEncoder,\n",
        "    \"TransformerDecoder\": keras_nlp.layers.TransformerDecoder\n",
        "})\n",
        "loaded_model_te.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RcRYOaxa8MNv"
      },
      "outputs": [],
      "source": [
        "telugu_vocab = telugu_vectorization.get_vocabulary()\n",
        "telugu_index_lookup = dict(zip(range(len(telugu_vocab)), telugu_vocab))\n",
        "start_index = telugu_vocab.index(config.start_token)\n",
        "end_index = telugu_vocab.index(config.end_token)\n",
        "unk_index = telugu_vocab.index(\"[UNK]\")\n",
        "def decode_sequence_te(model_te, input_sentence, filtered_values = [start_index, end_index, unk_index]):\n",
        "    tokenized_input_sentence = english_vectorization([input_sentence])\n",
        "    decoded_sentence = [start_index] + [0] * (config.sequence_length)\n",
        "    for i in range(config.sequence_length):\n",
        "        decoded_sentence_constant = tf.constant([decoded_sentence[:config.sequence_length]])\n",
        "        predictions = model_te([tokenized_input_sentence, decoded_sentence_constant])\n",
        "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
        "        decoded_sentence[i + 1] = sampled_token_index\n",
        "        if sampled_token_index == end_index:\n",
        "            break\n",
        "    components = [telugu_index_lookup[c] for c in decoded_sentence if c not in filtered_values]\n",
        "    return \" \".join(components)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UgPPrdth8OC6"
      },
      "outputs": [],
      "source": [
        "for i in tqdm(np.random.choice(len(data_te), 10)):\n",
        "    item = data_te.iloc[i]\n",
        "    translated = decode_sequence_te(loaded_model_te, item[\"english\"])\n",
        "    print(\"English:\", item[\"english\"])\n",
        "    print(\"telugu:\", item[\"telugu\"].replace(\"[start] \", \"\").replace(\" [end]\", \"\"))\n",
        "    print(\"Translated:\", translated)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQk8COnd8j9B"
      },
      "source": [
        "***TAMIL***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jIRzmewtqZnw"
      },
      "outputs": [],
      "source": [
        "def translate_user_input(input_sentence):\n",
        "    translated = decode_sequence_ta(loaded_model_ta, input_sentence)\n",
        "\n",
        "    print(\"Input English:\", input_sentence)\n",
        "    print(\"Translated Tamil:\", translated)\n",
        "\n",
        "# Example usage:\n",
        "user_input_sentence = \"Where is Tom?\"\n",
        "translate_user_input(user_input_sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BTyo9Sc1xQu"
      },
      "source": [
        "***HINDI***\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SHM2MGfCvIWM"
      },
      "outputs": [],
      "source": [
        "def translate_user_input(input_sentence):\n",
        "    translated = decode_sequence_hi(loaded_model_hi, input_sentence)\n",
        "\n",
        "    print(\"Input English:\", input_sentence)\n",
        "    print(\"Translated hindi:\", translated)\n",
        "\n",
        "# Example usage:\n",
        "user_input_sentence = \"Tom is happy\"\n",
        "translate_user_input(user_input_sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYS8Dvn117Zj"
      },
      "source": [
        "***MALAYALAM***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PpU9Rryg5b7E"
      },
      "outputs": [],
      "source": [
        "def translate_user_input(input_sentence):\n",
        "    translated = decode_sequence_ml(loaded_model_ml, input_sentence)\n",
        "\n",
        "    print(\"Input English:\", input_sentence)\n",
        "    print(\"Translated malayalam:\", translated)\n",
        "\n",
        "# Example usage:\n",
        "user_input_sentence = \"We know her\"\n",
        "translate_user_input(user_input_sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cyAMp6Y67SM"
      },
      "source": [
        "***TELUGU***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XCIHH9sR8QC-"
      },
      "outputs": [],
      "source": [
        "def translate_user_input(input_sentence):\n",
        "    translated = decode_sequence_te(loaded_model_te, input_sentence)\n",
        "\n",
        "    print(\"Input English:\", input_sentence)\n",
        "    print(\"Translated telugu:\", translated)\n",
        "\n",
        "# Example usage:\n",
        "user_input_sentence = \"Tom is happy\"\n",
        "translate_user_input(user_input_sentence)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2b50c797055c4bad8d01c5465035d8be": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d36b94d59da485b86d492751b078bb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d61818451b64fca9f1a4669558586bb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c46869b0dd948b08a12c65d2acab800": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b50c797055c4bad8d01c5465035d8be",
            "placeholder": "​",
            "style": "IPY_MODEL_d85750bbbc2b41f683c50c579d983eaa",
            "value": "100%"
          }
        },
        "8c5b7fb222844b2e8464860efd0887e0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa64439777404f7ea934d8364f1f9089": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c5b7fb222844b2e8464860efd0887e0",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f7e1a3d9f0b94f06a3b2cfc775b461c6",
            "value": 10
          }
        },
        "b71a376a7c3644389df03183fd3238f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b749c02cb73b47158aaecbe53bac8d76",
            "placeholder": "​",
            "style": "IPY_MODEL_2d36b94d59da485b86d492751b078bb3",
            "value": " 10/10 [00:02&lt;00:00,  4.66it/s]"
          }
        },
        "b749c02cb73b47158aaecbe53bac8d76": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c49409961d21456fbea6a908bb377dab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8c46869b0dd948b08a12c65d2acab800",
              "IPY_MODEL_aa64439777404f7ea934d8364f1f9089",
              "IPY_MODEL_b71a376a7c3644389df03183fd3238f5"
            ],
            "layout": "IPY_MODEL_5d61818451b64fca9f1a4669558586bb"
          }
        },
        "d85750bbbc2b41f683c50c579d983eaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7e1a3d9f0b94f06a3b2cfc775b461c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}